{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from matplotlib.font_manager import _rebuild; _rebuild()\n",
    "#Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io as spio\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, StandardScaler\n",
    "from yellowbrick.classifier import ROCAUC, PrecisionRecallCurve\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator for reproducibility.\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load in dataset.\n",
    "data = spio.loadmat(\"features_10s_2019-01-30.mat\");\n",
    "features = data['features'];\n",
    "labels = data['labels_features'];\n",
    "animal_id_features = data['animal_id_features'].transpose();\n",
    "animal_names = data['animal_names'].transpose();\n",
    "feat_names = data['feat_names'];\n",
    "col_names = pd.DataFrame(feat_names)\n",
    "\n",
    "# Label each feature column with its description.\n",
    "def find_between(s):\n",
    "    start = '\\'';\n",
    "    end = '\\'';\n",
    "    return((s.split(start))[1].split(end)[0])\n",
    "cols = [];\n",
    "c_names = col_names.values.ravel();\n",
    "\n",
    "for x in range(len(c_names)):\n",
    "    name = str (c_names[x]);\n",
    "    cols.append(find_between(name))\n",
    "\n",
    "# Create a DataFrame of features with columns named & rows labeled.\n",
    "feat_data = pd.DataFrame(data=features,columns=cols)\n",
    "feat_data.insert(0,'AnimalId',animal_id_features)\n",
    "feat_data.insert(0,'Labels',labels.transpose())\n",
    "\n",
    "# Select the features corresponding to one animal.\n",
    "def get_single_animal_features(df, index) :\n",
    "    return df.loc[df['AnimalId'] == index]\n",
    "\n",
    "# Delete the rows corresponding to the animal left out.\n",
    "def get_loo_features(df, index):\n",
    "    df[df.AnimalId != index]\n",
    "    return df\n",
    "\n",
    "def get_pooled_features(df):\n",
    "    return feat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with optimal gridsearched parameters.\n",
    "def get_mlp():\n",
    "    return MLPClassifier(\n",
    "        max_iter=1500,\n",
    "        verbose=51,\n",
    "        tol=0.000001, \n",
    "        learning_rate='constant',\n",
    "        alpha=0.001,\n",
    "        solver='adam',\n",
    "        batch_size=512,\n",
    "        activation='tanh')\n",
    "\n",
    "# Plot ROC curve, AUC.\n",
    "def plot_rocauc(animal_id, X_train, y_train, X_test, y_test, mlp):\n",
    "    classes=[\"Normal\",\"Pre-Ictal\",\"Seizure\"]\n",
    "    v = ROCAUC(mlp, classes=classes)\n",
    "    v.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "    v.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "    ROC_title = \"ROCAUC_{}.png\".format(animal_id)\n",
    "    v.poof(outpath=ROC_title) # Save plot w unique title\n",
    "\n",
    "# Plot the precision-recall curve.\n",
    "def plot_precision_recall(animal_id, X_train, y_train, X_test, y_test, mlp):\n",
    "    v = PrecisionRecallCurve(mlp) \n",
    "    v.fit(X_train, y_train) # Fit the training data to the visualizer\n",
    "    v.score(X_test, y_test) # Evaluate the model on the test data\n",
    "    PR_title = \"PR_{}.png\".format(animal_id)\n",
    "    v.poof(outpath=PR_title) # Save plot w unique title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce MLPClassification for each animal in the dataset.\n",
    "for i in range(1,13):\n",
    "    index = i\n",
    "    animal_id = animal_names[index-1][0]\n",
    "    sys.stdout = open(\"log_{}.txt\".format(animal_id), \"w\")\n",
    "    print(\"Animal chosen: %s\" % animal_names[index - 1][0])\n",
    "\n",
    "    # Get features.\n",
    "    single_animal_features = get_single_animal_features(feat_data, index);\n",
    "\n",
    "    # Get only labels corresponding to selected animal's features.\n",
    "    y = single_animal_features['Labels']\n",
    "    X = single_animal_features.drop(columns={'Labels','AnimalId'})\n",
    "\n",
    "    # Split data into training (80%) and testing (20%).\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2);\n",
    "\n",
    "    # Standardize the data since the MLP is sensitive to feature scaling.\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit only to the training data.\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Apply the transformations to the data.\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Construct multi-layer perceptron classifier.\n",
    "    mlp_classifier = get_mlp()\n",
    "    \n",
    "    # Produce graphs.\n",
    "    plot_rocauc(animal_id, X_train, y_train, X_test, y_test, mlp_classifier);\n",
    "    plot_precision_recall(animal_id, X_train, y_train, X_test, y_test, mlp_classifier);\n",
    "    \n",
    "    # Run model with 4-fold cross validation. Report mean accuracy.\n",
    "    scores = cross_val_score(mlp, X_train, y_train, cv=4)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    sys.stdout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
